{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inconsistent Data Entry\n",
    "\n",
    "- get unique .unique(); get unique and their .value_counts()\n",
    "- convert text data to upper/lower case .str.upper()\n",
    "- delect the tailing whitespace using .str.strip\n",
    "- what is fuzzywuzzy package. how to use this package. use tab to try different method\n",
    "- learn how to use different methods of a package. Learn what is the argument of each method\n",
    "- Using fuzzywuzzy to deal with text inconsistent\n",
    "- Learn how to use a ratio to get the most similar words\n",
    "- How to write a function. Know your argument and know what would you want to get using some methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get our environment set up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cache entry deserialization failed, entry ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached fuzzywuzzy-0.16.0-py2.py3-none-any.whl\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "pip.main(['install', 'fuzzywuzzy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuanq\\Anaconda3\\envs\\py36\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# modules we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helpful modules\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import chardet\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'Windows-1252', 'confidence': 0.73, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "# look at the first ten thousand bytes to guess the character encoding\n",
    "with open(\"PakistanSuicideAttacks Ver 11 (30-November-2017).csv\", 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "\n",
    "# check what the character encoding might be\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then read it in with the correct encoding. (If this look unfamiliar to you, check out [yesterday's challenge](https://www.kaggle.com/rtatman/data-cleaning-challenge-character-encodings/).) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our dat\n",
    "suicide_attacks = pd.read_csv(\"PakistanSuicideAttacks Ver 11 (30-November-2017).csv\", \n",
    "                              encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to get started! You can, as always, take a moment here to look at the data and get familiar with it. :)\n",
    "\n",
    "\n",
    "# Do some preliminary text pre-processing\n",
    "___\n",
    "\n",
    "For this exercise, I'm interested in cleaning up the \"City\" column to make sure there's no data entry inconsistencies in it. We could go through and check each row by hand, of course, and hand-correct inconsistencies when we find them. There's a more efficient way to do this though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATTOCK', 'Attock ', 'Bajaur Agency', 'Bannu', 'Bhakkar ', 'Buner',\n",
       "       'Chakwal ', 'Chaman', 'Charsadda', 'Charsadda ', 'D. I Khan',\n",
       "       'D.G Khan', 'D.G Khan ', 'D.I Khan', 'D.I Khan ', 'Dara Adam Khel',\n",
       "       'Dara Adam khel', 'Fateh Jang', 'Ghallanai, Mohmand Agency ',\n",
       "       'Gujrat', 'Hangu', 'Haripur', 'Hayatabad', 'Islamabad',\n",
       "       'Islamabad ', 'Jacobabad', 'KURRAM AGENCY', 'Karachi', 'Karachi ',\n",
       "       'Karak', 'Khanewal', 'Khuzdar', 'Khyber Agency', 'Khyber Agency ',\n",
       "       'Kohat', 'Kohat ', 'Kuram Agency ', 'Lahore', 'Lahore ',\n",
       "       'Lakki Marwat', 'Lakki marwat', 'Lasbela', 'Lower Dir', 'MULTAN',\n",
       "       'Malakand ', 'Mansehra', 'Mardan', 'Mohmand Agency',\n",
       "       'Mohmand Agency ', 'Mohmand agency', 'Mosal Kor, Mohmand Agency',\n",
       "       'Multan', 'Muzaffarabad', 'North Waziristan', 'North waziristan',\n",
       "       'Nowshehra', 'Orakzai Agency', 'Peshawar', 'Peshawar ', 'Pishin',\n",
       "       'Poonch', 'Quetta', 'Quetta ', 'Rawalpindi', 'Sargodha',\n",
       "       'Sehwan town', 'Shabqadar-Charsadda', 'Shangla ', 'Shikarpur',\n",
       "       'Sialkot', 'South Waziristan', 'South waziristan', 'Sudhanoti',\n",
       "       'Sukkur', 'Swabi ', 'Swat', 'Swat ', 'Taftan',\n",
       "       'Tangi, Charsadda District', 'Tank', 'Tank ', 'Taunsa',\n",
       "       'Tirah Valley', 'Totalai', 'Upper Dir', 'Wagah', 'Zhob', 'bannu',\n",
       "       'karachi', 'karachi ', 'lakki marwat', 'peshawar', 'swat'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'City' column\n",
    "cities = suicide_attacks['City'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "cities.sort()\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at this, I can see some problems due to inconsistent data entry: 'Lahore' and 'Lahore ', for example, or 'Lakki Marwat' and 'Lakki marwat'.\n",
    "\n",
    "The first thing I'm going to do is make everything lower case (I can change it back at the end if I like) and remove any white spaces at the beginning and end of cells. Inconsistencies in capitalizations and trailing white spaces are very common in text data and you can fix a good 80% of your text data entry inconsistencies by doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "suicide_attacks['City'] = suicide_attacks['City'].str.lower()\n",
    "# remove trailing white spaces\n",
    "suicide_attacks['City'] = suicide_attacks['City'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to tackle more difficult inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KPK            251\n",
       "FATA            70\n",
       "Punjab          64\n",
       "Sindh           35\n",
       "Baluchistan     31\n",
       "Capital         20\n",
       "Balochistan     16\n",
       "AJK              6\n",
       "Fata             3\n",
       "Name: Province, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your turn! Take a look at all the unique values in the \"Province\" column. \n",
    "# Then convert the column to lowercase and remove any trailing white spaces\n",
    "suicide_attacks['Province'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "suicide_attacks['Province'] = suicide_attacks['Province'].str.lower()\n",
    "# remove trailing white spaces\n",
    "suicide_attacks['Province'] = suicide_attacks['Province'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use fuzzy matching to correct inconsistent data entry\n",
    "___\n",
    "\n",
    "Alright, let's take another look at the city column and see if there's any more data cleaning we need to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n",
       "       'chaman', 'charsadda', 'd. i khan', 'd.g khan', 'd.i khan',\n",
       "       'dara adam khel', 'fateh jang', 'ghallanai, mohmand agency',\n",
       "       'gujrat', 'hangu', 'haripur', 'hayatabad', 'islamabad',\n",
       "       'jacobabad', 'karachi', 'karak', 'khanewal', 'khuzdar',\n",
       "       'khyber agency', 'kohat', 'kuram agency', 'kurram agency',\n",
       "       'lahore', 'lakki marwat', 'lasbela', 'lower dir', 'malakand',\n",
       "       'mansehra', 'mardan', 'mohmand agency',\n",
       "       'mosal kor, mohmand agency', 'multan', 'muzaffarabad',\n",
       "       'north waziristan', 'nowshehra', 'orakzai agency', 'peshawar',\n",
       "       'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n",
       "       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n",
       "       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n",
       "       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n",
       "       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'City' column\n",
    "cities = suicide_attacks['City'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "cities.sort()\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does look like there are some remaining inconsistencies: 'd. i khan' and 'd.i khan' should probably be the same. (I [looked it up](https://en.wikipedia.org/wiki/List_of_most_populous_cities_in_Pakistan) and 'd.g khan' is a seperate city, so I shouldn't combine those.) \n",
    "\n",
    "I'm going to use the [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy) package to help identify which string are closest to each other. This dataset is small enough that we could probably could correct errors by hand, but that approach doesn't scale well. (Would you want to correct a thousand errors by hand? What about ten thousand? Automating things as early as possible is generally a good idea. Plus, it’s fun! :)\n",
    "\n",
    "> **Fuzzy matching:** The process of automatically finding text strings that are very similar to the target string. In general, a string is considered \"closer\" to another one the fewer characters you'd need to change if you were transforming one string into another. So \"apple\" and \"snapple\" are two changes away from each other (add \"s\" and \"n\") while \"in\" and \"on\" and one change away (rplace \"i\" with \"o\"). You won't always be able to rely on fuzzy matching 100%, but it will usually end up saving you at least a little time.\n",
    "\n",
    "Fuzzywuzzy returns a ratio given two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we're going to get the ten strings from our list of cities that have the closest distance to \"d.i khan\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d. i khan', 100),\n",
       " ('d.i khan', 100),\n",
       " ('d.g khan', 88),\n",
       " ('khanewal', 50),\n",
       " ('sudhanoti', 47),\n",
       " ('hangu', 46),\n",
       " ('kohat', 46),\n",
       " ('dara adam khel', 45),\n",
       " ('chaman', 43),\n",
       " ('mardan', 43)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top 10 closest matches to \"d.i khan\"\n",
    "matches = fuzzywuzzy.process.extract(\"d.i khan\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# take a look at them\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d. i khan', 100),\n",
       " ('d.i khan', 100),\n",
       " ('d.g khan', 88),\n",
       " ('khanewal', 50),\n",
       " ('sudhanoti', 47)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top 10 closest matches to \"d.i khan\"\n",
    "matches = fuzzywuzzy.process.extractBests(\"d.i khan\", cities, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# take a look at them\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('d. i khan', 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top 10 closest matches to \"d.i khan\"\n",
    "matches = fuzzywuzzy.process.extractOne(\"d.i khan\", cities, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# take a look at them\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that two of the items in the cities are very close to \"d.i khan\": \"d. i khan\" and \"d.i khan\". We can also see the \"d.g khan\", which is a seperate city, has a ratio of 88. Since we don't want to replace \"d.g khan\" with \"d.i khan\", let's replace all rows in our City column that have a ratio of > 90 with \"d. i khan\". \n",
    "\n",
    "To do this, I'm going to write a function. (It's a good idea to write a general purpose function you can reuse if you think you might have to do a specific task more than once or twice. This keeps you from having to copy and paste code too often, which saves time and can help prevent mistakes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to replace rows in the provided column of the provided dataframe\n",
    "# that match the provided string above the provided ratio with the provided string\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # get the top 10 closest matches to our input string\n",
    "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
    "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "    # only get matches with a ratio > 90\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    # let us know the function's done\n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function, we can put it to the test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# use the function we just wrote to replace close matches to \"d. i khan\" with \"d.i khan\"\n",
    "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"d.i khan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kuram agency', 100),\n",
       " ('kurram agency', 96),\n",
       " ('bajaur agency', 72),\n",
       " ('khyber agency', 72),\n",
       " ('orakzai agency', 69),\n",
       " ('mohmand agency', 62),\n",
       " ('mosal kor, mohmand agency', 61),\n",
       " ('ghallanai, mohmand agency', 50),\n",
       " ('gujrat', 44),\n",
       " ('d.g khan', 40)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your turn! It looks like 'kuram agency' and 'kurram agency' should\n",
    "# be the same city. Correct the dataframe so that they are.\n",
    "# get the closest matches to \"kuram agency\"\n",
    "matches = fuzzywuzzy.process.extract(\"kuram agency\", cities, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# take a look at them\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# use the function we just wrote to replace close matches to \"kurram agency\" with \"kuram agency\"\n",
    "replace_matches_in_column(df=suicide_attacks, column='City', string_to_match=\"kuram agency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['islamabad', 'karachi', 'quetta', 'rawalpindi', 'north waziristan',\n",
       "       'kohat', 'attock', 'sialkot', 'lahore', 'swat', 'hangu', 'bannu',\n",
       "       'lasbela', 'malakand', 'peshawar', 'd.i khan', 'lakki marwat',\n",
       "       'tank', 'gujrat', 'charsadda', 'kuram agency', 'shangla',\n",
       "       'bajaur agency', 'south waziristan', 'haripur', 'sargodha',\n",
       "       'nowshehra', 'mohmand agency', 'dara adam khel', 'khyber agency',\n",
       "       'mardan', 'bhakkar', 'orakzai agency', 'buner', 'd.g khan',\n",
       "       'pishin', 'chakwal', 'upper dir', 'muzaffarabad', 'totalai',\n",
       "       'multan', 'lower dir', 'sudhanoti', 'poonch', 'mansehra', 'karak',\n",
       "       'swabi', 'shikarpur', 'sukkur', 'chaman', 'khanewal', 'fateh jang',\n",
       "       'taftan', 'tirah valley', 'wagah', 'zhob', 'taunsa', 'jacobabad',\n",
       "       'shabqadar-charsadda', 'khuzdar', 'ghallanai, mohmand agency',\n",
       "       'hayatabad', 'mosal kor, mohmand agency', 'sehwan town',\n",
       "       'tangi, charsadda district'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide_attacks['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
